{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56696a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def load_model_and_create_feature_extractor(model_path):\n",
    "    \"\"\"\n",
    "    Load the trained model and create a feature extractor\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the trained model\n",
    "    \n",
    "    Returns:\n",
    "        Feature extractor model\n",
    "    \"\"\"\n",
    "    # Load the model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Create a feature extractor model (using the output before the final classification layer)\n",
    "    # For the provided model architecture, this is the output after GlobalAveragePooling2D\n",
    "    feature_layer = 'global_average_pooling2d'\n",
    "    \n",
    "    # Create a new model that outputs features\n",
    "    feature_extractor = Model(\n",
    "        inputs=model.input,\n",
    "        outputs=model.get_layer(feature_layer).output\n",
    "    )\n",
    "    \n",
    "    return feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbe77753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(feature_extractor, image_dir, batch_size=32):\n",
    "    \"\"\"\n",
    "    Extract features from images in a directory\n",
    "    \n",
    "    Args:\n",
    "        feature_extractor: Model for feature extraction\n",
    "        image_dir: Directory containing images\n",
    "        batch_size: Batch size for processing\n",
    "    \n",
    "    Returns:\n",
    "        Features, labels, and filenames\n",
    "    \"\"\"\n",
    "    # Data generator for feature extraction\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create generator\n",
    "    generator = datagen.flow_from_directory(\n",
    "        image_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False  # Don't shuffle to keep track of filenames\n",
    "    )\n",
    "    \n",
    "    # Extract features\n",
    "    features = []\n",
    "    labels = []\n",
    "    filenames = []\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(generator.class_indices.keys())\n",
    "    \n",
    "    # Calculate steps\n",
    "    steps = np.ceil(generator.samples / batch_size).astype(int)\n",
    "    \n",
    "    print(f\"Extracting features from {generator.samples} images...\")\n",
    "    \n",
    "    # Process batches\n",
    "    for i in tqdm(range(steps)):\n",
    "        batch_images, batch_labels = next(generator)\n",
    "        batch_features = feature_extractor.predict(batch_images)\n",
    "        \n",
    "        features.append(batch_features)\n",
    "        labels.append(np.argmax(batch_labels, axis=1))\n",
    "        filenames.extend([os.path.basename(f) for f in generator.filenames[i*batch_size:(i+1)*batch_size]])\n",
    "    \n",
    "    # Concatenate batches\n",
    "    features = np.vstack(features)\n",
    "    labels = np.concatenate(labels)\n",
    "    \n",
    "    return features, labels, filenames, class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5259cb4",
   "metadata": {},
   "source": [
    "## tsne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9657ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tsne(features, labels, class_names, output_path=None):\n",
    "    \"\"\"\n",
    "    Visualize features using t-SNE\n",
    "    \n",
    "    Args:\n",
    "        features: Extracted features\n",
    "        labels: Class labels\n",
    "        class_names: Names of classes\n",
    "        output_path: Path to save the visualization\n",
    "    \"\"\"\n",
    "    # Apply t-SNE\n",
    "    print(\"Applying t-SNE dimensionality reduction...\")\n",
    "    tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
    "    features_tsne = tsne.fit_transform(features)\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Plot each class\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        idx = labels == i\n",
    "        plt.scatter(features_tsne[idx, 0], features_tsne[idx, 1], label=class_name, alpha=0.7)\n",
    "    \n",
    "    plt.title('t-SNE Visualization of Image Features')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.legend(title='Classes')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Save if output path is provided\n",
    "    if output_path:\n",
    "        plt.savefig(output_path)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e31f32",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54375034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pca(features, labels, class_names, output_path=None):\n",
    "    \"\"\"\n",
    "    Visualize features using PCA\n",
    "    \n",
    "    Args:\n",
    "        features: Extracted features\n",
    "        labels: Class labels\n",
    "        class_names: Names of classes\n",
    "        output_path: Path to save the visualization\n",
    "    \"\"\"\n",
    "    # Apply PCA\n",
    "    print(\"Applying PCA dimensionality reduction...\")\n",
    "    pca = PCA(n_components=2)\n",
    "    features_pca = pca.fit_transform(features)\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Plot each class\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        idx = labels == i\n",
    "        plt.scatter(features_pca[idx, 0], features_pca[idx, 1], label=class_name, alpha=0.7)\n",
    "    \n",
    "    plt.title('PCA Visualization of Image Features')\n",
    "    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} explained variance)')\n",
    "    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} explained variance)')\n",
    "    plt.legend(title='Classes')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Save if output path is provided\n",
    "    if output_path:\n",
    "        plt.savefig(output_path)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316be94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_activation_maps(model, image_path, class_names, output_path=None):\n",
    "    \"\"\"\n",
    "    Visualize activation maps (Grad-CAM) for a given image\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        image_path: Path to image\n",
    "        class_names: Class names\n",
    "        output_path: Path to save visualization\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    # Apply preprocessing\n",
    "    img_yuv = cv2.cvtColor(img_resized, cv2.COLOR_RGB2YUV)\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "    img_eq = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
    "    img_blur = cv2.GaussianBlur(img_eq, (3, 3), 0)\n",
    "    \n",
    "    # Normalize\n",
    "    img_normalized = img_blur.astype(np.float32) / 255.0\n",
    "    img_batch = np.expand_dims(img_normalized, axis=0)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(img_batch)[0]\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    confidence = predictions[predicted_class]\n",
    "    \n",
    "    # Create Grad-CAM heatmap\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    # Find the last convolutional layer\n",
    "    last_conv_layer = None\n",
    "    for layer in reversed(model.layers):\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            last_conv_layer = layer.name\n",
    "            break\n",
    "    \n",
    "    if last_conv_layer is None:\n",
    "        print(\"Could not find a convolutional layer in the model\")\n",
    "        return\n",
    "    \n",
    "    # Create a model that outputs both the predictions and the activations\n",
    "    grad_model = Model(\n",
    "        inputs=model.inputs,\n",
    "        outputs=[model.get_layer(last_conv_layer).output, model.output]\n",
    "    )\n",
    "    \n",
    "    # Compute gradient of the predicted class with respect to the activations\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_batch)\n",
    "        class_prediction = predictions[:, predicted_class]\n",
    "    \n",
    "    # Gradients of the predicted class with respect to the output feature map\n",
    "    grads = tape.gradient(class_prediction, conv_outputs)\n",
    "    \n",
    "    # Pool the gradients across the channels\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    \n",
    "    # Weight the channels by the gradient values\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
    "    \n",
    "    # Normalize the heatmap\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    heatmap = heatmap.numpy()\n",
    "    \n",
    "    # Resize heatmap to original image size\n",
    "    heatmap = cv2.resize(heatmap, (img_resized.shape[1], img_resized.shape[0]))\n",
    "    \n",
    "    # Convert heatmap to RGB\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Superimpose heatmap on original image\n",
    "    superimposed_img = heatmap * 0.4 + img_resized\n",
    "    superimposed_img = np.clip(superimposed_img, 0, 255).astype('uint8')\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img_resized)\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Heatmap\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(heatmap)\n",
    "    plt.title('Activation Heatmap')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Superimposed\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(superimposed_img)\n",
    "    plt.title(f'Prediction: {class_names[predicted_class]}\\nConfidence: {confidence:.2%}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if output_path:\n",
    "        plt.savefig(output_path)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ad0c5",
   "metadata": {},
   "source": [
    "## Misclassified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a0c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_misclassified(model, dataset_dir, output_dir=None, batch_size=32):\n",
    "    \"\"\"\n",
    "    Find and visualize misclassified images\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        dataset_dir: Directory containing test images\n",
    "        output_dir: Directory to save visualizations\n",
    "        batch_size: Batch size for processing\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with misclassification details\n",
    "    \"\"\"\n",
    "    # Create output directory if needed\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Data generator\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Get test generator\n",
    "    test_dir = os.path.join(dataset_dir, 'test')\n",
    "    test_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "    \n",
    "    # Make predictions\n",
    "    steps = np.ceil(test_generator.samples / batch_size).astype(int)\n",
    "    predictions = model.predict(test_generator, steps=steps)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Get true labels\n",
    "    true_classes = test_generator.classes[:len(predicted_classes)]\n",
    "    \n",
    "    # Find misclassified images\n",
    "    misclassified_indices = np.where(predicted_classes != true_classes)[0]\n",
    "    \n",
    "    if len(misclassified_indices) == 0:\n",
    "        print(\"No misclassified images found!\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare results\n",
    "    misclassified_results = []\n",
    "    \n",
    "    print(f\"Found {len(misclassified_indices)} misclassified images\")\n",
    "    \n",
    "    # Process each misclassified image\n",
    "    for idx in misclassified_indices:\n",
    "        true_class = true_classes[idx]\n",
    "        pred_class = predicted_classes[idx]\n",
    "        confidence = predictions[idx][pred_class]\n",
    "        image_path = test_generator.filepaths[idx]\n",
    "        image_name = os.path.basename(image_path)\n",
    "        \n",
    "        misclassified_results.append({\n",
    "            'image': image_name,\n",
    "            'true_class': class_names[true_class],\n",
    "            'predicted_class': class_names[pred_class],\n",
    "            'confidence': confidence,\n",
    "            'file_path': image_path\n",
    "        })\n",
    "        \n",
    "        # Visualize if output directory is provided\n",
    "        if output_dir:\n",
    "            # Load and preprocess image\n",
    "            img = cv2.imread(image_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Create visualization\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"True: {class_names[true_class]}\\nPredicted: {class_names[pred_class]} ({confidence:.2%})\")\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save\n",
    "            save_path = os.path.join(output_dir, f\"misclassified_{image_name}\")\n",
    "            plt.savefig(save_path)\n",
    "            plt.close()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(misclassified_results)\n",
    "    \n",
    "    # Save results to CSV\n",
    "    if output_dir:\n",
    "        results_df.to_csv(os.path.join(output_dir, 'misclassified_images.csv'), index=False)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fb222",
   "metadata": {},
   "source": [
    "## main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b8261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn_visualization(model_path, dataset_path, output_dir='visualization_results', \n",
    "                         image_path=None, mode='all'):\n",
    "    \"\"\"\n",
    "    Run CNN visualization with the specified parameters.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the trained model\n",
    "        dataset_path: Path to the dataset directory\n",
    "        output_dir: Directory to save results (default: 'visualization_results')\n",
    "        image_path: Path to a specific image for activation map visualization (optional)\n",
    "        mode: Visualization mode (options: 'tsne', 'pca', 'activation', 'misclassified', 'all')\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Get class names\n",
    "    # Try to load class names from a file next to the model\n",
    "    class_names_path = os.path.join(os.path.dirname(model_path), 'class_names.txt')\n",
    "    \n",
    "    if os.path.exists(class_names_path):\n",
    "        with open(class_names_path, 'r') as f:\n",
    "            class_names = [line.strip() for line in f.readlines()]\n",
    "        print(f\"Loaded {len(class_names)} classes from file: {class_names}\")\n",
    "    else:\n",
    "        # If class names file doesn't exist, try to get them from the test directory\n",
    "        test_dir = os.path.join(dataset_path, 'test')\n",
    "        if os.path.exists(test_dir):\n",
    "            datagen = ImageDataGenerator(rescale=1./255)\n",
    "            generator = datagen.flow_from_directory(\n",
    "                test_dir,\n",
    "                target_size=(224, 224),\n",
    "                batch_size=1,\n",
    "                class_mode='categorical',\n",
    "                shuffle=False\n",
    "            )\n",
    "            class_names = list(generator.class_indices.keys())\n",
    "            print(f\"Loaded {len(class_names)} classes from test directory: {class_names}\")\n",
    "        else:\n",
    "            print(\"Warning: Could not find class names file or test directory.\")\n",
    "            # Default to numeric class names\n",
    "            num_classes = model.layers[-1].output_shape[-1]\n",
    "            class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "            print(f\"Using default class names: {class_names}\")\n",
    "    \n",
    "    # Run visualizations based on mode\n",
    "    if mode in ['tsne', 'pca', 'all']:\n",
    "        # Extract features from test images\n",
    "        feature_extractor = load_model_and_create_feature_extractor(model_path)\n",
    "        test_dir = os.path.join(dataset_path, 'test')\n",
    "        \n",
    "        features, labels, filenames, _ = extract_features(\n",
    "            feature_extractor, \n",
    "            test_dir\n",
    "        )\n",
    "        \n",
    "        # t-SNE visualization\n",
    "        if mode in ['tsne', 'all']:\n",
    "            print(\"Generating t-SNE visualization...\")\n",
    "            tsne_output_path = os.path.join(output_dir, 'tsne_visualization.png')\n",
    "            visualize_tsne(features, labels, class_names, tsne_output_path)\n",
    "        \n",
    "        # PCA visualization\n",
    "        if mode in ['pca', 'all']:\n",
    "            print(\"Generating PCA visualization...\")\n",
    "            pca_output_path = os.path.join(output_dir, 'pca_visualization.png')\n",
    "            visualize_pca(features, labels, class_names, pca_output_path)\n",
    "    \n",
    "    # Activation map visualization\n",
    "    if mode in ['activation', 'all'] and image_path:\n",
    "        print(f\"Generating activation map for {image_path}...\")\n",
    "        activation_output_path = os.path.join(output_dir, 'activation_map.png')\n",
    "        visualize_activation_maps(model, image_path, class_names, activation_output_path)\n",
    "    \n",
    "    # Find misclassified images\n",
    "    if mode in ['misclassified', 'all']:\n",
    "        print(\"Finding misclassified images...\")\n",
    "        misclassified_output_path = os.path.join(output_dir, 'misclassified')\n",
    "        if not os.path.exists(misclassified_output_path):\n",
    "            os.makedirs(misclassified_output_path)\n",
    "        \n",
    "        misclassified_results = find_misclassified(\n",
    "            model, \n",
    "            dataset_path, \n",
    "            misclassified_output_path\n",
    "        )\n",
    "    \n",
    "    print(\"Visualization complete!\")\n",
    "    return \"All visualizations completed successfully\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c5b9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your paths\n",
    "MODEL_PATH = '/Users/anamikasaroha/Energy7_Week1/week_5/model/final_model.h5'\n",
    "DATASET_PATH = '/Users/anamikasaroha/Energy7_Week1/week_5/dataset_split'\n",
    "OUTPUT_DIR = 'visualization_results'\n",
    "IMAGE_PATH = '/Users/anamikasaroha/Energy7_Week1/week_5/dataset_split/test/159_160/sample_129_159_160.png'  # Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de934218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /Users/anamikasaroha/Energy7_Week1/week_5/model/final_model.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 classes from file: ['129_130', '159_160', 'PT101_102', 'PT119_120', 'PT_101_102', 'PT_101___102', 'PT_103_104', 'PT_109_110', 'PT_111___112', 'PT_119_120', 'PT_119___120', 'PT_121_122', 'PT_129_130', 'PT_135___136', 'PT_157___158', 'PT_189___190']\n",
      "Finding misclassified images...\n",
      "Found 240 images belonging to 16 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 841ms/step\n",
      "Found 117 misclassified images\n",
      "Visualization complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All visualizations completed successfully'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_cnn_visualization(MODEL_PATH, DATASET_PATH, OUTPUT_DIR, IMAGE_PATH, mode='misclassified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e324f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /Users/anamikasaroha/Energy7_Week1/week_5/model/final_model.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 classes from file: ['129_130', '159_160', 'PT101_102', 'PT119_120', 'PT_101_102', 'PT_101___102', 'PT_103_104', 'PT_109_110', 'PT_111___112', 'PT_119_120', 'PT_119___120', 'PT_121_122', 'PT_129_130', 'PT_135___136', 'PT_157___158', 'PT_189___190']\n",
      "Generating activation map for /Users/anamikasaroha/Energy7_Week1/week_5/dataset_split/test/159_160/sample_129_159_160.png...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Could not find a convolutional layer in the model\n",
      "Visualization complete!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All visualizations completed successfully'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_cnn_visualization(MODEL_PATH, DATASET_PATH, OUTPUT_DIR, IMAGE_PATH, mode='activation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e357ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf4aca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5adb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1628a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d4f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d5f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3a094",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
